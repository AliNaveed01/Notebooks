{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#suggested libraries for NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12681.192027</td>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7299.553863</td>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6372.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12703.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18995.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25296.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       "count  24783.000000  24783.000000  24783.000000        24783.000000   \n",
       "mean   12681.192027      3.243473      0.280515            2.413711   \n",
       "std     7299.553863      0.883060      0.631851            1.399459   \n",
       "min        0.000000      3.000000      0.000000            0.000000   \n",
       "25%     6372.500000      3.000000      0.000000            2.000000   \n",
       "50%    12703.000000      3.000000      0.000000            3.000000   \n",
       "75%    18995.500000      3.000000      0.000000            3.000000   \n",
       "max    25296.000000      9.000000      7.000000            9.000000   \n",
       "\n",
       "            neither         class  \n",
       "count  24783.000000  24783.000000  \n",
       "mean       0.549247      1.110277  \n",
       "std        1.113299      0.462089  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      1.000000  \n",
       "50%        0.000000      1.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        9.000000      2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1    !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ten = df['tweet'][:2]\n",
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    !!! rt @mayasolovely: as a woman you shouldn't...\n",
      "1    !!!!! rt @mleew17: boy dats cold...tyga dwn ba...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#converting the tweets in lower case\n",
    "lower = ten.str.lower()\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [!!!, rt, @mayasolovely:, as, a, woman, you, s...\n",
      "1    [!!!!!, rt, @mleew17:, boy, dats, cold...tyga,...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tokenized= lower.str.split()\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(tokenized):\n",
    "    bigram = []\n",
    "    for i in tokenized:\n",
    "        for j in range(len(i)-1):\n",
    "            bigram.append([i[j],i[j+1]])\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['!!!', 'rt'], ['rt', '@mayasolovely:'], ['@mayasolovely:', 'as'], ['as', 'a'], ['a', 'woman'], ['woman', 'you'], ['you', \"shouldn't\"], [\"shouldn't\", 'complain'], ['complain', 'about'], ['about', 'cleaning'], ['cleaning', 'up'], ['up', 'your'], ['your', 'house.'], ['house.', '&amp;'], ['&amp;', 'as'], ['as', 'a'], ['a', 'man'], ['man', 'you'], ['you', 'should'], ['should', 'always'], ['always', 'take'], ['take', 'the'], ['the', 'trash'], ['trash', 'out...'], ['!!!!!', 'rt'], ['rt', '@mleew17:'], ['@mleew17:', 'boy'], ['boy', 'dats'], ['dats', 'cold...tyga'], ['cold...tyga', 'dwn'], ['dwn', 'bad'], ['bad', 'for'], ['for', 'cuffin'], ['cuffin', 'dat'], ['dat', 'hoe'], ['hoe', 'in'], ['in', 'the'], ['the', '1st'], ['1st', 'place!!']]\n"
     ]
    }
   ],
   "source": [
    "print(bigrams(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(tokenized):\n",
    "    unique = []\n",
    "    for i in tokenized:\n",
    "        for j in i :\n",
    "            if(j  not in unique):\n",
    "                unique.append(j)\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!!!', 'rt', '@mayasolovely:', 'as', 'a', 'woman', 'you', \"shouldn't\", 'complain', 'about', 'cleaning', 'up', 'your', 'house.', '&amp;', 'man', 'should', 'always', 'take', 'the', 'trash', 'out...', '!!!!!', '@mleew17:', 'boy', 'dats', 'cold...tyga', 'dwn', 'bad', 'for', 'cuffin', 'dat', 'hoe', 'in', '1st', 'place!!']\n"
     ]
    }
   ],
   "source": [
    "token = unique_words(tokenized)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrammaker(tokenized):\n",
    "    bigram_unique = []\n",
    "    for i in range(len(ten)):\n",
    "        t = ten[i].lower().split()\n",
    "        for j in range(1,len(t)):\n",
    "            word = t[j-1] + \" \" + t[j]\n",
    "            if word not in bigram_unique:\n",
    "                bigram_unique.append(word)\n",
    "    return bigram_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!!! rt',\n",
       " 'rt @mayasolovely:',\n",
       " '@mayasolovely: as',\n",
       " 'as a',\n",
       " 'a woman',\n",
       " 'woman you',\n",
       " \"you shouldn't\",\n",
       " \"shouldn't complain\",\n",
       " 'complain about',\n",
       " 'about cleaning',\n",
       " 'cleaning up',\n",
       " 'up your',\n",
       " 'your house.',\n",
       " 'house. &amp;',\n",
       " '&amp; as',\n",
       " 'a man',\n",
       " 'man you',\n",
       " 'you should',\n",
       " 'should always',\n",
       " 'always take',\n",
       " 'take the',\n",
       " 'the trash',\n",
       " 'trash out...',\n",
       " '!!!!! rt',\n",
       " 'rt @mleew17:',\n",
       " '@mleew17: boy',\n",
       " 'boy dats',\n",
       " 'dats cold...tyga',\n",
       " 'cold...tyga dwn',\n",
       " 'dwn bad',\n",
       " 'bad for',\n",
       " 'for cuffin',\n",
       " 'cuffin dat',\n",
       " 'dat hoe',\n",
       " 'hoe in',\n",
       " 'in the',\n",
       " 'the 1st',\n",
       " '1st place!!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = bigrammaker(ten)\n",
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary  1st  about  always  amp   as  bad  boy  cleaning  cold  complain  \\\n",
      "sentence1   0.0    0.0     0.0  0.0  0.0  0.0  0.0       0.0   0.0       0.0   \n",
      "sentence2   0.0    0.0     0.0  0.0  0.0  0.0  0.0       0.0   0.0       0.0   \n",
      "sentence3   0.0    0.0     0.0  0.0  0.0  0.0  0.0       0.0   0.0       0.0   \n",
      "\n",
      "vocabulary  ...  should  shouldn  take  the  trash  tyga   up  woman  you  \\\n",
      "sentence1   ...     0.0      0.0   0.0  0.0    0.0   0.0  0.0    0.0  0.0   \n",
      "sentence2   ...     0.0      0.0   0.0  0.0    0.0   0.0  0.0    0.0  0.0   \n",
      "sentence3   ...     0.0      0.0   0.0  0.0    0.0   0.0  0.0    0.0  0.0   \n",
      "\n",
      "vocabulary  your  \n",
      "sentence1    0.0  \n",
      "sentence2    0.0  \n",
      "sentence3    0.0  \n",
      "\n",
      "[3 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ms Links\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "corpus = token\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "vect = tfidf.fit_transform(corpus)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['vocabulary'] = tfidf.get_feature_names()\n",
    "df['sentence1'] = vect.toarray()[0]\n",
    "df['sentence2'] = vect.toarray()[1]\n",
    "df['sentence3'] = vect.toarray()[2]\n",
    "df.set_index('vocabulary', inplace=True)\n",
    "print(df.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fd60b8bb15377d59e74e9fea1e7409c02a309b91caf5779becf2247a2e38203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
